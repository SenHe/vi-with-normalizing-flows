{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.distributions import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference algorithm:\n",
    "    \n",
    "Parameters: $\\phi$ variational, $\\theta$ generative\n",
    "    \n",
    "while not converged do:\n",
    "        \n",
    "$\\quad \\text{x = {Get mini batch}}\\\\\n",
    "\\quad z_0 ~ q_0(\\cdot | x)\\\\\n",
    "\\quad z_K = f_K( ... f_1(z_0) )\\\\\n",
    "\\quad F(x) \\approx F(x, z_K)\\\\\n",
    "\\quad \\Delta \\theta \\propto - \\nabla_\\theta F(x)\\\\\n",
    "\\quad \\Delta \\phi \\propto - \\nabla_\\phi F(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformation:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.training = None\n",
    "        self.log_det = None\n",
    "        \n",
    "    @property\n",
    "    def training(self):\n",
    "        return self._training\n",
    "    \n",
    "    @training.setter\n",
    "    def training(self, enable:bool):\n",
    "        if not enable:\n",
    "            self.log_det = None\n",
    "        self._training = enable\n",
    "    \n",
    "    def forward(self, zi, params):\n",
    "        if self.training:\n",
    "            self.log_det = torch.log( self.det( zi, params ).squeeze() + 1e-7 )\n",
    "        return self.transform( zi, params )\n",
    "    \n",
    "    def get_num_params(self):\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "class PlanarTransformation(Transformation):\n",
    "    \n",
    "    def __init__(self, dim:int, u:list=None, w:list=None, b:list=None, training:bool=True):\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.h = nn.Tanh()\n",
    "        self.training = training\n",
    "        \n",
    "    def get_num_params(self):\n",
    "        return self.dim * 2 + 1\n",
    "    \n",
    "    def transform(self, z, params):\n",
    "#         if torch.dot(self.w.data.squeeze(), self.u.data.squeeze()) < -1:\n",
    "#             print( \"adjusting u\")\n",
    "#             dotwu = torch.dot( self.w.data.squeeze(), self.u.data.squeeze() )\n",
    "#             self.u.data = self.u + ( -1 + torch.log( 1 + torch.exp( dotwu ) ) - dotwu ) \\\n",
    "#                             * self.w.data / torch.sqrt( torch.dot( self.w.data.squeeze(), self.w.data.squeeze() ) )\n",
    "        return z + params[self.dim:-1].unsqueeze(0) * self.h( F.linear(z, params[:self.dim].unsqueeze(0), params[-1]) )\n",
    "    \n",
    "    def h_deriv(self, x):\n",
    "        ff = self.h( x )\n",
    "        return 1 - ff * ff\n",
    "    \n",
    "    def psi(self, z, params):\n",
    "        return self.h_deriv( F.linear(z, params[:self.dim].unsqueeze(0), params[-1]) ) * params[:self.dim].unsqueeze(0)\n",
    "    \n",
    "    def det(self, z, params):\n",
    "        return ( 1 + torch.mm( self.psi(z, params), params[self.dim:-1].unsqueeze(0).t() ) ).abs()\n",
    "\n",
    "\n",
    "class RadialTransformation(Transformation):\n",
    "    \n",
    "    def __init__(self, dim:int, z0=None, alpha=None, beta=None, training:bool=True):\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.training = training\n",
    "        \n",
    "    def get_num_params(self):\n",
    "        return self.dim + 2\n",
    "        \n",
    "    def transform(self, z, params):\n",
    "#         if self.beta < -self.alpha:\n",
    "#             print( \"adjusting beta\")\n",
    "#             self.beta.data = -self.alpha + torch.log( 1 + torch.exp( self.beta ) )\n",
    "        r = torch.norm( ( z - params[:self.dim].unsqueeze(0) ), p=2, dim=1, keepdim=True )\n",
    "        return z + params[-1] * ( self.h( r, params[-2] ) * (z - params[:self.dim].unsqueeze(0)) )\n",
    "    \n",
    "    def h(self, r, alpha):\n",
    "        return 1 / (alpha + r)\n",
    "    \n",
    "    def h_deriv(self, r, alpha):\n",
    "        ff = self.h( r, alpha )\n",
    "        return - ff * ff\n",
    "    \n",
    "    def det(self, z, params):\n",
    "        r = torch.norm( ( z - params[:self.dim].unsqueeze(0) ), p=2, dim=1, keepdim=True )\n",
    "        tmp = 1 + params[-1] * self.h( r, params[-2] )\n",
    "        return torch.clamp(tmp.pow(self.dim - 1) * (tmp + params[-1] * self.h_deriv(r, params[-2]) * r), min=1e-7)\n",
    "    \n",
    "class NormalizingFlow:\n",
    "    \n",
    "    def __init__( self, transformation, dim:int, K:int, transformations=None ):\n",
    "        self.K = K\n",
    "        self.dim = dim\n",
    "        \n",
    "        if transformations is None:\n",
    "            transformations = [ transformation( dim ) for i in range( K ) ]\n",
    "        self.flow = transformations\n",
    "        self.nParams = self.flow[0].get_num_params()\n",
    "        \n",
    "    def get_last_log_det(self):\n",
    "        return self.flow[-1].log_det\n",
    "    \n",
    "    def get_sum_log_det(self):\n",
    "        ret = 0\n",
    "        for trans in self.flow:\n",
    "            ret += trans.log_det\n",
    "        return ret\n",
    "        \n",
    "    def forward( self, z, params ):\n",
    "        for i, transf in enumerate( self.flow ):\n",
    "            z = transf.forward(z, params[i])\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=100, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a large batch will be used to compute average flow parameters after training\n",
    "large_batch = []\n",
    "for i, (data, _) in enumerate(train_loader):\n",
    "    if i > 1000:\n",
    "        break\n",
    "    large_batch.append(data)\n",
    "large_batch = torch.cat(large_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoderNormalizingFlow(nn.Module):\n",
    "    def __init__(self, flow_transform, flow_latent, flow_len):\n",
    "        super(VariationalAutoencoderNormalizingFlow, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.flow = NormalizingFlow(flow_transform, flow_latent, flow_len )\n",
    "        self.fc23 = nn.Linear(400, self.flow.nParams * flow_len )\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1), self.fc23(h1).mean(dim=0).chunk(self.flow.K, dim=0)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar, params = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.flow.forward(z, params)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(make_grid(img.data.numpy()))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = VariationalAutoencoderNormalizingFlow(RadialTransformation, 20, 32)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function_VAENF(recon_x, x, mu, logvar, sum_log_det):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    KLD = KLD / x.size(0) - sum_log_det.mean()  # mean over batch\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "def train_VAENF(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        sum_log_det = model.flow.get_sum_log_det()\n",
    "        loss = loss_function_VAENF(recon_batch, data, mu, logvar, sum_log_det)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test_VAENF(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            sum_log_det = model.flow.get_sum_log_det()\n",
    "            test_loss += loss_function_VAENF(recon_batch, data, mu, logvar, sum_log_det).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(100, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         '../results/reconstruction_VAENF_' + str(model.flow.K) + \"_\" + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 547.741406\n",
      "====> Epoch: 1 Average loss: 137.2828\n",
      "====> Test set loss: 102.2544\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 98.476064\n",
      "====> Epoch: 2 Average loss: 85.3859\n",
      "====> Test set loss: 86.9399\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 84.899004\n",
      "====> Epoch: 3 Average loss: 78.5412\n",
      "====> Test set loss: 80.7491\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 79.119424\n",
      "====> Epoch: 4 Average loss: 75.4289\n",
      "====> Test set loss: 77.5757\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 76.253413\n",
      "====> Epoch: 5 Average loss: 73.4791\n",
      "====> Test set loss: 75.1793\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 73.531030\n",
      "====> Epoch: 6 Average loss: 72.1626\n",
      "====> Test set loss: 73.4380\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 71.635566\n",
      "====> Epoch: 7 Average loss: 71.1915\n",
      "====> Test set loss: 72.3078\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 70.323950\n",
      "====> Epoch: 8 Average loss: 70.5028\n",
      "====> Test set loss: 71.6908\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 69.653491\n",
      "====> Epoch: 9 Average loss: 69.9461\n",
      "====> Test set loss: 71.4568\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 69.057827\n",
      "====> Epoch: 10 Average loss: 69.4464\n",
      "====> Test set loss: 70.9226\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10 + 1):\n",
    "    train_VAENF(epoch)\n",
    "    test_VAENF(epoch)\n",
    "    with torch.no_grad():\n",
    "        _ , _, params = model.encode(large_batch.view(-1, 784))\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "        sample = model.decode( model.flow.forward( sample, params ) ).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "        '../results/sample_VAENF_' + str(model.flow.K) + \"_\" + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [100/60000 (0%)]\tLoss: 520.192422\n",
      "====> Epoch: 1 Average loss: 163.7044\n",
      "====> Test set loss: 129.3005\n",
      "Train Epoch: 2 [100/60000 (0%)]\tLoss: 128.591484\n",
      "====> Epoch: 2 Average loss: 122.1876\n",
      "====> Test set loss: 117.5843\n",
      "Train Epoch: 3 [100/60000 (0%)]\tLoss: 116.660557\n",
      "====> Epoch: 3 Average loss: 114.7716\n",
      "====> Test set loss: 112.3378\n",
      "Train Epoch: 4 [100/60000 (0%)]\tLoss: 111.183389\n",
      "====> Epoch: 4 Average loss: 111.6862\n",
      "====> Test set loss: 110.3866\n",
      "Train Epoch: 5 [100/60000 (0%)]\tLoss: 108.903408\n",
      "====> Epoch: 5 Average loss: 109.8727\n",
      "====> Test set loss: 108.9313\n",
      "Train Epoch: 6 [100/60000 (0%)]\tLoss: 106.509854\n",
      "====> Epoch: 6 Average loss: 108.6934\n",
      "====> Test set loss: 108.6331\n",
      "Train Epoch: 7 [100/60000 (0%)]\tLoss: 107.039883\n",
      "====> Epoch: 7 Average loss: 107.8680\n",
      "====> Test set loss: 107.4852\n",
      "Train Epoch: 8 [100/60000 (0%)]\tLoss: 105.359277\n",
      "====> Epoch: 8 Average loss: 107.2541\n",
      "====> Test set loss: 107.0832\n",
      "Train Epoch: 9 [100/60000 (0%)]\tLoss: 104.430303\n",
      "====> Epoch: 9 Average loss: 106.7469\n",
      "====> Test set loss: 107.1155\n",
      "Train Epoch: 10 [100/60000 (0%)]\tLoss: 103.609580\n",
      "====> Epoch: 10 Average loss: 106.3030\n",
      "====> Test set loss: 106.2739\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 1:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(100, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         '../results/reconstruction_VAE_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "for epoch in range(1, 10 + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "        '../results/sample_VAE_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
